# 简介

本次项目基于[PIP](https://github.com/Xinyu-Yi/PIP)模型用于对乒乓球挥拍姿势的捕捉，并在模型后面再训练一个分类头，用于对运动姿势的评价。最终希望实现的效果是能够自主设计一套传感器系统，且尽量减少传感器的数量，当运动员穿戴上传感器后，传感器将收集到的IMU数据回传到计算机端的模型进行处理，并对姿势进行打分。

![image-20230119092450506](.\img\image-20230119092450506.png)

# 实验

## 1.环境配置

参考1环境配置.md文件

## 2.收集乒乓球运动员数据集用于训练分类头

如简介中的图片所示，我们希望是通过PIP能够捕捉到运动员的挥拍姿势，然后再在后面训练一个分类头用于评价。但是由于目前缺乏精确的传感器，无法得到精确的IMU测量数据，从而无法通过PIP获得精确的运动姿势。所以在等待采购传感器的这段时间，通过阅读DIP（https://doi.org/10.48550/arXiv.1810.04703），这篇论文应该也算是比较早使用6个IMU进行动作捕捉的方法，该论文主要提供了一些思路，他首先是使用AMASS数据集（该数据集囊括很多网上已有，但是格式不同的mocap数据集，作者将这些数据集格式统一为SMPL模型的格式），通过代码合成IMU测量数据，因为是合成的数据，所以并不是真实的。然后其将这些合成的数据集用于训练模型，最后再通过传感器收集真实的IMU测量数据用于测试模型，其流程如下图所示。
![image-20230119103115299](.\img\image-20230119103115299.png)所以我们也可以通过生成SMPL模型，然后也合成相应的IMU数据，用于测试PIP，但是问题就是如何获得SMPL模型参数。我的做法是通过[VIBE](https://github.com/mkocabas/VIBE)方法，该方法只需要通过单目摄像头获得的视频，即可得到SMPL模型的参数，效果如下图所示：

![image-20230119103445708](.\img\image-20230119103445708.png)

DIP方法是开源的项目，里面包含了[合成数据的代码](https://github.com/eth-ait/dip18/tree/master/data_synthesis)，另外，采用VIBE的原因是VIBE生成的模型正好是SMPL模型，通过导出生成的模型参数，就可以合成IMU数据，但是VIBE方法毕竟是通过单目视频生成的模型，其效果并不是特别好，存在一些抖动，但是目前只是为了测试一下PIP方法是否能够还原运动员的动作，也无所谓是否准确，等到有精确的传感器时，可以使用精确的IMU测量数据进行姿态还原。

## 3.收集运动员数据集用于训练网络

基于前面的操作，如果能够顺利通过合成IMU数据还原运动员姿势，接下来便可以收集运动员数据集用于训练分类头。但是数据集的收集存在一些问题，因为每个人的身高臂展等不同，所以对于一个运动员来说哪种姿势才算是标准，鉴于目前研究的不多，我的想法是将身高臂展等也作为网络输入参数，用于训练模型
![image-20230119104748702](.\img\image-20230119104748702.png)

## 4.制作传感器

等待更新。。。
